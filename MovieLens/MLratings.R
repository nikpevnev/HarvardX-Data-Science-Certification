#########################################################
# Create edx and final_holdout_test sets
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(tibble)
library(knitr)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

options(timeout = 120)

dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)

movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)

ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
                         stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))

movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
                        stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
  mutate(movieId = as.integer(movieId))

movielens <- left_join(ratings, movies, by = "movieId")

# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
# set.seed(1) # if using R 3.5 or earlier
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in final hold-out test set are also in edx set
final_holdout_test <- temp %>%
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from final hold-out test set back into edx set
removed <- anti_join(temp, final_holdout_test)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)


##########################################################
# MovieLens Project
# Nik Pevnev
# 3/19/2025
##########################################################

# -----
# Intro
# -----

# MovieLens project is based on creating a rating machine learning algorithm trained on provided edx data and RMSE tested with final_holdout_test set.
# Final deliverables of the project will be: .Rmd file, .DF document, and an R script.
# Below is the general info of a dataset worked with

# -------
# Dataset
# -------

# MovieLens 10 million movie rating dataset (http://grouplens.org/datasets/movielens/10m/) contains 10m ratings with 100,000 tags applied to 10,000 movies by 72,000 users.
# Dataset is then split per project requirements into 2 datasets to create efficient analysis of machine learning algorithm created: edx with 9000055 rows and final_holdout_test with 999999 rows, each dataset has 6 columns.

# Check data sets created
head(final_holdout_test)
dim(final_holdout_test) # [1] 999999      6
head(edx)
dim(edx) # [1] 9000055       6

# How many movies with 1 rating only? - 126 movies
ratings_count <- edx %>%
  group_by(movieId) %>%
  summarise(ratings_count = n())

movies_with_one_rating <- ratings_count %>%
  filter(ratings_count == 1)

num_movies_with_one_rating <- nrow(movies_with_one_rating)
num_movies_with_one_rating

# ----------------
# Machine Learning
# ----------------

# Method 1 - mean of ratings can be used as a basis for predicting what
# This is most simple prediction of each rating that is constant and represents mean of all movie ratings

# (1) Calculate mean across all edx ratings
method1Predictions_Mean <- mean(edx$rating)
# method1Predictions # [1] 3.512465
# On average rating given by user is 3.51

# (2) Calculate RMSE of method 1 prediction
rmse1 <- RMSE(final_holdout_test$rating, method1Predictions_Mean)
rmse1

######################################################

# Method 2 - Remediate effects of each movie rating on the final predicted score based on mean of ratings as a basis and their difference
# This is a manual process of predicting ratings and using join functions to recalculate each mean prediction by movie effect deviation

# (1) Generate movie effect lookup table that can be used 
# as a lookup to normalize simple mean prediction
movieEffectLookupTable <- edx %>%
  group_by(movieId) %>% # Group by movie to calculate movie bias
  summarize(movieBias = mean(rating - method1Predictions_Mean))
# movieEffectLookupTable

# (2) Calculate predictions based on 
# final_holdout_test dataset and assess its RMSE
method2Predictions <- final_holdout_test %>%
  left_join(movieEffectLookupTable, by = "movieId") %>%  
  mutate(tailoredPrediction 
         = method1Predictions_Mean + coalesce(movieBias, 0)) %>%
  pull(tailoredPrediction)
# method2Predictions

# (3) Calculate RMSE of method 2 prediction
rmse2 <- RMSE(final_holdout_test$rating, method2Predictions)
rmse2

######################################################

# Method 3 - Remediate effects of user bias by introducing a new variable in linear model prediction, the final predicted score is based on mean of ratings as a basis and movie effects from method 2
# This is a manual process of predicting ratings and using join functions to recalculate each mean prediction by movie effect and user bias deviations

# (1) Generate user effect lookup table that can be used 
# as a lookup to normalize simple mean prediction
userEffectLookupTable <- edx %>%
  left_join(movieEffectLookupTable, by='movieId') %>%
  group_by(userId) %>% # Group by user to calculate user bias
  summarize(userBias = mean(rating - method1Predictions_Mean - movieBias))
# userEffectLookupTable

# (2) Calculate predictions based on 
# final_holdout_test dataset and assess its RMSE
method3Predictions <- final_holdout_test %>%
  left_join(movieEffectLookupTable, by = "movieId") %>%  
  left_join(userEffectLookupTable, by='userId') %>%
  mutate(tailoredPrediction 
         = method1Predictions_Mean + coalesce(userBias, 0) + coalesce(movieBias, 0)) %>%
  pull(tailoredPrediction)
# method3Predictions

# (3) Calculate RMSE of method 3 prediction
rmse3 <- RMSE(final_holdout_test$rating, method3Predictions)
rmse3

######################################################

# Method 4 - Remediate effects of both movie and user bias with regularization method to avoid incorrect rating estimates more accurately
# We are going to minimize prediction error by introducing a regularization parameter Lambda to prevent overfitting issues, where We introduce a regularization parameter n()+l to adjust movie ratings bias for movies with less ratings than popular ones
# This is a multi-step process where we first find most optimal lambda for most efficient accuracy. Once we know best value to take for prediction model, we import it to our method 4 algorithm.

# (1) Calculate list of optimal prediction regression models that can fit best to predict the best

optimalResult <- optimize(function(l) {
  movieBiasLookUp <- edx %>%
    group_by(movieId) %>%
    summarize(movieBias = sum(rating - method1Predictions_Mean) / (n() + l))
  
  userBiasLookUp <- edx %>%
    left_join(movieBiasLookUp, by = "movieId") %>%
    group_by(userId) %>%
    summarize(userBias = sum(rating - coalesce(movieBias, 0) - method1Predictions_Mean) / (n() + l))
  
  method4Predictions <- final_holdout_test %>%
    left_join(movieBiasLookUp, by = "movieId") %>%
    left_join(userBiasLookUp, by = "userId") %>%
    mutate(tailoredPrediction = method1Predictions_Mean + movieBias + userBias) %>%
    pull(tailoredPrediction)
  
  return(RMSE(final_holdout_test$rating, method4Predictions))
  
}, lower = 0, upper = 10)

# (2) Extract the most optimal lambda and RMSE
optimalLambda <- optimalResult$minimum
optimalLambda
optimalRMSE <- optimalResult$objective
optimalRMSE

# (3) Calculate predictions based on 
# final_holdout_test dataset and assess its RMSE
movieBiasLookUp <- edx %>%
  group_by(movieId) %>%
  summarize(movieBias = sum(rating - method1Predictions_Mean) / (n() + optimalLambda))

userBiasLookUp <- edx %>%
  left_join(movieBiasLookUp, by = "movieId") %>%
  group_by(userId) %>%
  summarize(userBias = sum(rating - coalesce(movieBias, 0) - method1Predictions_Mean) / (n() + optimalLambda))

method4Predictions <- final_holdout_test %>%
  left_join(movieBiasLookUp, by = "movieId") %>%
  left_join(userBiasLookUp, by = "userId") %>%
  mutate(tailoredPrediction = method1Predictions_Mean + movieBias + userBias) %>%
  pull(tailoredPrediction)

# (4) Calculate RMSE of method 4 prediction
rmse4 <- RMSE(final_holdout_test$rating, method4Predictions)
rmse4

# -------
# Summary
# -------

# Here is summary of all RMSE for methods used in machine learning section. We can observe gradual increase in algorithm accuracy as we add more granularity to account for statistical variations.

rmseSummary <- tibble(
  Method = c("Method 1: Mean", "Method 2: Movie Effect"
             , "Method 3: Movie & User Effects", "Method 4: Regularized Movie & User Effects"),
  RMSE = c(rmse1, rmse2, rmse3, rmse4)
)

kable(rmseSummary, caption = "RMSE Comparison of Different Methods")

#######################################################
####################### END ###########################
#######################################################